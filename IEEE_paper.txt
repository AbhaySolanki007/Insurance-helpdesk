# A Tiered, Multi-Agent Architecture for Scalable and Reliable Automated Insurance Customer Support

**Author(s):** [Your Name/Team Name Here]
**Affiliation:** [Your Organization Here]
**Email:** [Your Contact Email Here]

---

***Abstract***—**This paper presents the architecture and implementation of a novel, tiered, multi-agent system for automating customer support in the insurance domain. The system is designed to enhance service efficiency, ensure operational reliability, and scale cost-effectively by deploying two distinct levels of AI agents: a Level 1 (L1) agent for rapid, high-volume query handling, and a Level 2 (L2) agent for complex, escalated issue resolution requiring external tool use. We detail the system's backend, built with Python, Flask, and the LangChain framework, and a frontend-managed escalation protocol that ensures a seamless user experience. This paper elaborates on key AI methodologies, including the ReAct (Reason+Act) framework for traceable agentic behavior, Retrieval-Augmented Generation (RAG) for knowledge grounding, and a Human-in-the-Loop (HITL) validation pattern for critical actions. Furthermore, we propose a comprehensive evaluation framework with relevant performance metrics and discuss the critical security, compliance, and ethical considerations necessary for deploying such a system in a regulated industry. The resulting architecture provides a robust, scalable, and auditable blueprint for modern customer service automation.**

***Keywords—Artificial Intelligence, AI Agents, Customer Support, Large Language Models (LLM), LangChain, Tiered Architecture, ReAct Framework, Retrieval-Augmented Generation (RAG), Financial Services, InsurTech.***

---

### I. INTRODUCTION

The customer support landscape in the insurance industry is undergoing a paradigm shift, driven by escalating consumer expectations for immediate, personalized, and 24/7 service. However, traditional support models, which are heavily reliant on human agents, face significant challenges. These include high operational costs, with up to 25% of every premium dollar consumed by operating expenses [3], difficulties in scaling during peak periods, and inconsistencies in service quality. Studies indicate that less than a third of insurance customers are satisfied with their current providers [3], and a significant portion (41%) are willing to switch providers due to a lack of digital capabilities [3]. This highlights a critical gap between customer expectations and the service delivered.

The advent of powerful Large Language Models (LLMs) has created an opportunity to reimagine customer service through AI-driven automation. AI agents, powered by these models, can handle a vast spectrum of tasks, from answering simple queries to processing complex claims [1]. However, deploying a single, monolithic AI agent presents a difficult trade-off. A highly capable agent, while powerful, is often computationally expensive and may be underutilized for the high volume of simple, repetitive queries that dominate support channels. Conversely, a basic chatbot, while cost-effective, lacks the sophisticated reasoning and tool-use capabilities required for complex problem-solving, leading to high frustration and escalation rates.

To address this dichotomy, this paper introduces a tiered, multi-agent architecture specifically designed for an insurance helpdesk. Our primary contribution is the design and implementation of a two-level agentic system that strategically balances cost, capability, and reliability. This system is composed of:

1.  A lightweight **Level 1 (L1) agent**, optimized for cost-effective handling of initial triage and frequently asked questions (FAQs) through a Retrieval-Augmented Generation (RAG) pipeline.
2.  A more powerful **Level 2 (L2) agent**, equipped with an advanced LLM and a suite of secure tools to manage complex, escalated issues that require interaction with external services like Jira or email.
3.  A clearly defined **escalation protocol**, managed by the client-side application, that facilitates a seamless and context-aware handover between the agent tiers.
4.  The systematic application of the **ReAct (Reason+Act) framework** [5] to ensure that all agent actions are preceded by traceable, auditable reasoning steps, enhancing system interpretability and trustworthiness.
5.  A built-in **Human-in-the-Loop (HITL)** validation step for critical L2 agent actions, providing an essential safety guardrail in a regulated environment.

This paper provides a detailed technical blueprint of the system, covering its architecture, component implementation, core AI methodologies, and a framework for its evaluation and governance.

### II. SYSTEM ARCHITECTURE

The system is designed on a decoupled, service-oriented architecture that separates concerns between different layers of support, orchestration, and data management. The foundational concept is a tiered escalation model where the agent's complexity and capabilities are matched to the user's query complexity.

#### A. The Tiered Escalation Model
The core of our design is a two-tiered agent hierarchy (see Fig. 1). This model is a strategic choice to optimize for performance, scalability, and operational cost.

*   **Level 1 (L1) Agent - The Triage Specialist:** This agent serves as the initial point of contact for all user interactions. Its primary function is to handle a high volume of common queries by retrieving information from a curated knowledge base. It is designed to be fast and computationally inexpensive, using a smaller, efficient LLM. If the agent determines a query is beyond its knowledge scope, detects user frustration through keyword analysis, or is explicitly asked to escalate, it triggers the escalation protocol.

*   **Level 2 (L2) Agent - The Resolution Specialist:** This agent is a more powerful and privileged entity, engaged only for complex or escalated cases. It is powered by a more advanced LLM, granting it superior reasoning capabilities, and is equipped with a broader set of tools to perform actions on external systems (e.g., creating a support ticket, sending a formal email). Its operational cost is higher, justifying its use only when necessary.

The escalation path is managed by the frontend application. The L1 agent is prompted to output a specific, machine-readable string (`"...L2...."`) when it identifies a need for escalation. The frontend application monitors for this trigger in the L1 agent's response payload. Upon detection, it makes a new API call to a separate endpoint dedicated to the L2 agent. This approach, while creating a dependency on the client, simplifies the backend routing logic and avoids the need for a more complex and stateful orchestration engine for this specific use case.

```mermaid
graph TD
    subgraph "User Interaction"
        UI(Frontend Application)
    end

    subgraph "Backend Services (Flask Application)"
        subgraph "Agent Tier 1"
            L1_Endpoint["/predict/l1 API"]:::api
            L1_Agent["L1 Agent (ReAct)"]:::agent
            L1_Tools["Tools: faq_search, get_user_data"]:::tool
        end

        subgraph "Agent Tier 2"
            L2_Endpoint["/predict/l2 API"]:::api
            L2_Agent["L2 Agent (ReAct + HITL)"]:::agent
            L2_Tools["Tools: create_ticket, search_ticket, send_email"]:::tool
        end

        subgraph "Core Infrastructure"
            DB[(Database: User History)]:::db
            RAG[RAG Pipeline: ChromaDB + Embeddings]:::service
            Jira(Jira Service):::ext
            Email(Email Service):::ext
        end
    end

    UI -- "1. Initial Query" --> L1_Endpoint
    L1_Endpoint --> L1_Agent
    L1_Agent -- "2. Reason+Act" --> L1_Tools
    L1_Tools -- "3. Retrieve Data" --> RAG
    L1_Agent -- "4. Response (with L2 trigger?)" --> UI
    L1_Agent -- "5. Log Turn" --> DB

    UI -- "6. If L2 Triggered, New API Call" --> L2_Endpoint
    L2_Endpoint -- "7. Generate Summary" --> L2_Agent
    L2_Agent -- "8. Reason+Act" --> L2_Tools
    L2_Tools -- "9. Execute Action" --> Jira
    L2_Tools -- "9. Execute Action" --> Email
    L2_Agent -- "10. Final Resolution" --> UI
    L2_Agent -- "11. Log Turn" --> DB
    
    classDef api fill:#e6f2ff,stroke:#0066cc
    classDef agent fill:#cde4ff,stroke:#004a99
    classDef tool fill:#e0e0e0,stroke:#333
    classDef db fill:#fff2cc,stroke:#ff9900
    classDef service fill:#d4edda,stroke:#155724
    classDef ext fill:#f8d7da,stroke:#721c24
```
*Fig. 1. A detailed diagram of the system architecture, illustrating the tiered agent model, the frontend-managed escalation flow, and the interaction with backend and external services.*

### III. CORE COMPONENTS AND IMPLEMENTATION

The system is implemented in Python, utilizing several open-source libraries and frameworks to accelerate development and ensure robustness. The backend is served via a Flask web application.

#### A. L1 Agent Implementation
The L1 agent, defined in `backend/ai/L1_agent.py`, is built using the LangChain framework. It employs a `create_react_agent` constructor, which is ideal for tasks requiring explicit, step-by-step reasoning that can be easily logged and audited.

*   **Model:** A lightweight and fast LLM from Google's Gemini family (`gemini-1.5-flash-latest`) is used to minimize latency and cost for high-volume interactions.
*   **Prompting:** The agent's behavior is governed by a detailed system prompt that defines its persona as a "friendly and helpful insurance support assistant." The prompt contains explicit instructions on when and how to escalate, including watching for keywords indicating user frustration (e.g., "angry," "supervisor," "complaint") or queries that fall outside its knowledge domain.
*   **Tools:** Its toolset is intentionally restricted to read-only actions to adhere to the principle of least privilege:
    *   `faq_search`: Queries a vector database to find answers to FAQs. This tool is the interface to the RAG pipeline.
    *   `get_user_data` & `get_policy_data`: Fetches user-specific information (e.g., name, address, policy numbers) from the application's primary database.

#### B. L2 Agent Implementation
The L2 agent is a more sophisticated and powerful agent designed for action-oriented tasks.

*   **Model:** A more capable LLM is used to handle the increased complexity of its multi-step reasoning, workflow adherence, and tool usage.
*   **Prompting & Workflow:** The L2 agent's prompt is highly structured. It includes a mandatory placeholder for an `{escalation_summary}` to provide immediate context from the preceding L1 interaction. This summary is generated by a separate LLM call within the `/predict/l2` endpoint before the L2 agent is invoked. The prompt also enforces a strict, multi-step workflow for critical tasks. For instance, before creating a support ticket, it MUST confirm the generated ticket summary and description with the user. This implements a crucial HITL safety pattern.
*   **Tools:** The L2 agent has access to all L1 tools, plus additional privileged tools for interacting with external systems:
    *   `create_ticket`: Interfaces with the `JiraService` to create a new support ticket.
    *   `search_ticket`: Queries Jira for the status of an existing ticket.
    *   `send_email`: Uses the `EmailService` to send formal communications to the user.

#### C. Backend Orchestration and State Management
The Flask application in `app.py` serves as the central orchestrator for the agentic system.
1.  **Service Initialization:** On startup, the application creates singleton instances of the `UnifiedSupportChain` (for RAG) and the L1/L2 agent executors, ensuring efficient resource use.
2.  **API Endpoints:** It exposes the `/predict/l1` and `/predict/l2` endpoints, each routing requests to the appropriate agent executor.
3.  **Conversation History Management:** The backend is responsible for state management. For each user request, it retrieves the user's conversation history from a persistent database (`get_user_history`), formats it for the prompt, and after the agent's turn, appends the latest interaction and saves it back (`update_user_history`). This ensures that context is maintained across multiple turns and even across different agent tiers.

#### D. Tooling and Service Integration
The agents' tools are decoupled from the core agent logic, promoting a modular and maintainable design.

*   **Tool Definition (`tools.py`):** This module acts as a factory for creating and providing tools to the agents. A significant design choice here is the use of Pydantic models to define the expected schema for each tool's input. This provides strong type-checking and validation, adding a layer of robustness against malformed or unexpected inputs generated by the LLM.
*   **Retrieval-Augmented Generation (`unified_chain.py`):** The `UnifiedSupportChain` class encapsulates the full RAG pipeline. It leverages `ChromaDB` as a vector store for FAQ documents and uses `GoogleGenerativeAIEmbeddings` to convert text into vector representations. When the `faq_search` tool is called, this class performs a semantic similarity search to find the most relevant document chunks and returns them to the agent. This grounds the L1 agent in a trusted knowledge source, mitigating hallucination for factual queries.
*   **External Service Wrappers (`services/`):** Modules like `jira_service.py` and `email_service.py` act as wrappers around external APIs. They handle the specifics of authentication, request formatting, and error handling for these services. The agents' tools call these internal services, abstracting away the complexity of direct external API interaction.

### IV. KEY AI METHODOLOGIES AND DESIGN PATTERNS

The system's effectiveness is rooted in several modern AI engineering patterns.

*   **ReAct Framework:** As proposed by Yao et al. [5], the ReAct framework is central to our agent design. By instructing the LLM to generate an explicit `Thought` before each `Action`, we produce a transparent and auditable execution trace. This is invaluable for debugging, monitoring, and ensuring the agent behaves as expected. The interleaved `Thought, Action, Observation` sequence allows the agent to perform dynamic reasoning and course-correct based on the outcomes of its actions.

*   **Prompt Engineering as Configuration:** The system's operational logic is primarily defined through carefully engineered system prompts rather than being hard-coded. This "prompt-as-configuration" paradigm provides significant flexibility. Modifying the L1 agent's escalation policy or adjusting the L2 agent's workflow for ticket creation can often be achieved by updating the prompt text, allowing for rapid iteration and adaptation without a full software development cycle.

*   **Human-in-the-Loop (HITL) for Safety:** For high-stakes actions, the L2 agent employs a HITL pattern. The agent is explicitly forbidden by its prompt from using the `create_ticket` tool until it has presented a summary of the proposed ticket to the user and received explicit confirmation. This pattern is critical in a regulated domain like insurance, as it prevents the AI from taking irreversible actions based on a potential misunderstanding, thereby building user trust and ensuring operational safety.

### V. EVALUATION AND PERFORMANCE METRICS

To quantitatively assess the system's performance and business impact, we propose a framework based on standard customer service KPIs [6], [7], adapted for an AI-agent context.

| Metric                     | Description                                                                                             | Target for L1 Agent | Target for L2 Agent |
|----------------------------|---------------------------------------------------------------------------------------------------------|---------------------|---------------------|
| **Chatbot Resolution Rate**  | Percentage of interactions handled and resolved solely by the agent without needing to escalate.          | > 60%               | N/A (Always Human)  |
| **Escalation Rate**          | Percentage of L1 interactions that result in a handoff to the L2 agent.                                 | < 40%               | N/A                 |
| **Average Handle Time (AHT)**| Average duration of a conversation from start to finish.                                                | < 3 minutes         | < 10 minutes        |
| **Task Success Rate (TSR)**  | Percentage of L2 interactions where the intended task (e.g., ticket creation) was successfully completed. | N/A                 | > 95%               |
| **User Satisfaction (CSAT)** | Post-chat survey score (e.g., 1-5) measuring user satisfaction with the interaction.                    | > 4.0 / 5.0         | > 4.2 / 5.0         |
| **Tool Selection Accuracy**  | Percentage of times the agent selects the correct tool for a given task.                               | > 98%               | > 98%               |

*Table 1: Proposed Key Performance Indicators (KPIs) for evaluating the tiered agent system.*

Continuous monitoring of these metrics will provide actionable insights for iterative improvement, such as refining L1 prompts to improve its resolution rate or enhancing L2 tools to increase its task success rate.

### VI. SECURITY, COMPLIANCE, AND ETHICAL CONSIDERATIONS

Deploying an autonomous agent in the financial services industry necessitates a rigorous approach to security and compliance [8], [9]. Our architecture incorporates several layers of governance.

*   **Data Privacy and PII Handling:** All interactions with the LLM and internal services are conducted over secure, encrypted channels. The system is designed to avoid logging Personally Identifiable Information (PII) where possible. Furthermore, when interacting with third-party LLM APIs, enterprise-grade privacy features are enabled to prevent customer data from being used for model training.
*   **Principle of Least Privilege:** The L1 agent operates with read-only access to data, minimizing its potential impact. The L2 agent is granted more permissions, but its ability to perform actions is still strictly confined to its defined toolset. The agents do not have arbitrary code execution capabilities or direct access to production databases.
*   **Auditability and Traceability:** The ReAct framework provides a natural audit trail for every agent decision. Every `Thought` and `Action` is logged, allowing compliance teams to reconstruct the entire decision-making process for any given interaction, which is crucial for regulatory oversight.
*   **Guardrails Against Misuse:** The system prompts contain explicit "guardrails" that instruct agents on how to handle out-of-scope, malicious, or unethical requests. For example, agents are instructed to refuse to provide financial advice or process transactions outside their designated functions and to escalate such requests for human review.

### VII. CONCLUSION AND FUTURE WORK

This paper has detailed a tiered, multi-agent system for automated insurance customer support. By strategically combining two levels of AI agents with distinct capabilities and implementing robust design patterns like ReAct and HITL, the system provides an effective, scalable, and trustworthy solution that addresses key challenges in the insurance industry. The architecture demonstrates a pragmatic approach to balancing performance, cost, and safety.

Future work will focus on three key areas for enhancement:
1.  **Backend Orchestration:** The most significant architectural improvement will be to migrate from a frontend-managed escalation to a dedicated backend orchestration engine or state machine (e.g., using LangGraph). This will centralize the routing logic, making the system more robust and self-contained, and removing the dependency on the client application.
2.  **Toolset Expansion and Autonomy:** We plan to cautiously expand the L2 agent's toolset to include more complex actions, such as directly processing simple claims or updating user policy information via secure APIs. This will require developing more sophisticated validation and HITL patterns.
3.  **Proactive Support and Personalization:** The system can be evolved to provide proactive support. By analyzing user data, the system could identify potential issues (e.g., an upcoming policy expiration, a likely claim event) and initiate a conversation, transforming the helpdesk from a reactive to a proactive customer engagement tool.

---
### REFERENCES
[1] Beam.ai, "AI Automation in Customer Service for Insurance," *Beam.ai Blog*, 2024. [Online]. Available: https://beam.ai/use-cases/ai-automation-in-customer-service-for-insurance
[2] Dasha.ai, "How to sell more to happier customers with your insurance call center without hiring more people," *Dasha.ai Blog*, 2020. [Online]. Available: https://dasha.ai/en-us/blog/ai-insurance-customer-assistance
[3] Liferay, "20 Must-Know Stats for Insurers in 2022," *Liferay Blog*, 2022. [Online]. Available: https://www.liferay.com/blog/customer-experience/20-must-know-stats-for-insurers-in-2022
[4] Galileo, "Metrics for Evaluating LLM Chatbot Agents - Part 1," *Galileo Blog*, 2024. [Online]. Available: https://galileo.ai/blog/metrics-for-evaluating-llm-chatbots-part-1
[5] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao, "ReAct: Synergizing Reasoning and Acting in Language Models," in *International Conference on Learning Representations (ICLR)*, 2023. [Online]. Available: https://arxiv.org/abs/2210.03629
[6] AIMultiple Research, "Top 22 Metrics for Chatbot Analytics in 2024," *AIMultiple*, 2024. [Online]. Available: https://research.aimultiple.com/chatbot-analytics/
[7] Chatbase, "10 Essential Chatbot Analytics Metrics to Track Performance," *Chatbase Blog*, 2024. [Online]. Available: https://www.chatbase.co/blog/chatbot-analytics
[8] FINRA, "Artificial Intelligence in the Securities Industry: Key Challenges and Regulatory Considerations," *FINRA.org*, 2020. [Online]. Available: https://www.finra.org/rules-guidance/key-topics/fintech/report/artificial-intelligence-in-the-securities-industry/key-challenges
[9] Microsoft, "How responsible AI helps financial services manage risk and assure compliance," *Microsoft Industry Blogs*, 2024. [Online]. Available: https://www.microsoft.com/en-us/industry/blog/financial-services/2024/04/01/how-responsible-ai-helps-financial-services-manage-risk-and-assure-compliance/
[10] LangChain, "Agents," LangChain Documentation. [Online]. Available: https://python.langchain.com/docs/modules/agents/
[11] Pydantic, "Pydantic," Pydantic Documentation. [Online]. Available: https://docs.pydantic.dev/
[12] Chroma, "Chroma - The AI-native open-source embedding database." [Online]. Available: https://www.trychroma.com/ 